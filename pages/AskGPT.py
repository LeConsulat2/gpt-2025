import os
from dotenv import load_dotenv
import logging
import streamlit as st
from background import Black
from streamlit_extras.add_vertical_space import add_vertical_space
from typing import List, Dict

from langchain.chat_models import ChatOpenAI

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv(override=True)
openai_api_key = os.getenv("OPENAI_API_KEY")

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="GPT 4.1 AI ì±—ë´‡", page_icon="ğŸ¤–", layout="wide")

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s: %(message)s"
)
logger = logging.getLogger(__name__)

# ë‹¤í¬ í…Œë§ˆ ì ìš©
try:
    Black.dark_theme()
except Exception as e:
    logger.warning(f"ë‹¤í¬ í…Œë§ˆ ì ìš© ì‹¤íŒ¨: {e}")

# LLM ì´ˆê¸°í™”
if not openai_api_key:
    st.error("ğŸš¨ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì— í‚¤ë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
    raise ValueError("API í‚¤ ì—†ìŒ")

# (Pydantic v2 ëŒ€ì‘) ëª¨ë¸ ì¬ë¹Œë“œ
try:
    ChatOpenAI.model_rebuild()
except AttributeError:
    pass

llm = ChatOpenAI(
    model="gpt-4.1",
    temperature=0.3,
    api_key=openai_api_key,
    streaming=True,
)


class GPTChatAssistant:
    def __init__(self):
        self.chat = llm
        self.init_session_state()

    def init_session_state(self):
        default_system_prompt = {
            "role": "system",
            "content": (
                "ë‹¹ì‹ ì€ ìœ ìš©í•˜ê³  ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. "
                "ì‚¬ìš©ìê°€ ì–´ë–¤ ì§ˆë¬¸ì„ í•˜ë”ë¼ë„ ëª…í™•í•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”."
            ),
        }
        if "conversation" not in st.session_state:
            st.session_state.conversation = [default_system_prompt]
        st.session_state.chat_history = []

    def stream_response(self, conversation: List[Dict]):
        try:
            with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                response = self.chat.stream(conversation)
                full_response = ""
                for chunk in response:
                    if chunk.content:
                        full_response += chunk.content
                        yield full_response
        except Exception as e:
            logger.error(f"ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {e}")
            st.error(f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            yield "ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

    def run(self):
        st.title("ğŸ¤– GPT 4.1 AI ì±—ë´‡")
        st.markdown("*ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”. OpenAI GPT-4.1 ê¸°ë°˜ AI ì±—ë´‡ì…ë‹ˆë‹¤.*")

        with st.sidebar:
            st.header("ì±„íŒ… ì„¤ì •")
            if st.button("ğŸ”„ ëŒ€í™” ì´ˆê¸°í™”"):
                self.init_session_state()
                st.rerun()
            add_vertical_space(2)
            st.markdown("**ìµœê·¼ ì§ˆë¬¸ ê¸°ë¡**")
            for msg in st.session_state.chat_history[-5:]:
                st.markdown(f"- {msg}")

        for message in st.session_state.conversation[1:]:
            role = "user" if message["role"] == "user" else "assistant"
            st.chat_message(role).write(message["content"])

        if prompt := st.chat_input("ë¬´ì—‡ì´ë“  ì§ˆë¬¸í•´ë³´ì„¸ìš”..."):
            st.session_state.conversation.append({"role": "user", "content": prompt})
            st.session_state.chat_history.append(prompt)
            st.chat_message("user").write(prompt)

            response_placeholder = st.chat_message("assistant").empty()
            full_response = ""
            for response_chunk in self.stream_response(st.session_state.conversation):
                full_response = response_chunk
                response_placeholder.markdown(full_response)

            st.session_state.conversation.append(
                {"role": "assistant", "content": full_response}
            )


def main():
    try:
        assistant = GPTChatAssistant()
        assistant.run()
    except Exception as e:
        st.error(f"ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ: {e}")
        logger.critical(f"ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰ ì‹¤íŒ¨: {e}")


if __name__ == "__main__":
    main()
